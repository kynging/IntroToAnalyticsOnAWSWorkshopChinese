---
title: "6. 使用 EMR 转换数据"
chapter: false
weight: 6
---

这是一个可选模块。在本模块中，我们将使用 Amazon EMR 提交 pyspark 作业以读取原始数据并执行一些转换 + 聚合并将结果保留回 S3。

![](/images/1.LabGuide/emr.png)

#### 将脚本复制到 S3

在这一步中，我们将导航到 S3 控制台并创建几个用于 EMR 步骤的文件夹。

- 前往 S3 控制台：[https://s3.console.aws.amazon.com/s3/home?region=us-east-1](https://s3.console.aws.amazon.com/s3/home?region=us-east-1)
- 添加 PySpark 脚本：
  - 打开 **yourname-analytics-workshop-bucket**
	- 点击**创建文件夹**
	  - 创建一个名为 `scripts` 的新文件夹
	  - 点击**保存**
  - 打开**脚本**
	- 在本地下载此文件：[emr_pyspark.py](/files/emr_pyspark.py)
	- 在 S3 控制台中，单击**上传**：
	  - 点击**添加文件**，上传刚刚下载的 **emr_pyspark.py** 文件
	  - 点击**上传**
- 为 EMR 日志创建一个文件夹：
  - 打开 **yourname-analytics-workshop-bucket**
	- 点击**创建文件夹**
	  - 创建一个名为 `logs` 的新文件夹
	  - 点击**保存**

#### 创建 EMR 集群并添加步骤

在这一步中，我们将创建一个 EMR 集群并提交一个 Spark 步骤。

- 转到 EMR 控制台：[https://console.aws.amazon.com/elasticmapreduce/home?region=us-east-1#](https://console.aws.amazon.com/elasticmapreduce/home?region=us-east-1#)
- 点击**创建集群**
- 继续**创建集群 - 快速选项**
  - 为集群提供一个名称：`analytics-workshop-transformer`
  - 检查 **Logging** 选项并提供 S3 文件夹：
	- `s3://yourname-analytics-workshop-bucket/logs/`
  - 将**启动模式**更改为 **Step execution**
  - 在添加步骤下，从下拉列表中选择 **Spark 应用程序**
	- 点击**配置**
	- 在弹出窗口中，将 **Spark-submit** 选项留空
	- 对于应用程序位置，选择之前上传的脚本的位置 `s3://yourname-analytics-workshop-bucket/scripts/emr_pyspark.py`
	- 点击**选择**
	- 在**参数**下，输入您的 s3 存储桶的名称 `yourname-analytics-workshop-bucket`
	- 对于失败时的操作，从下拉列表中选择**终止集群**
	- 单击**添加**完成 EMR 创建集群

![](/images/1.LabGuide/emr-create-cluster.jpg)

  - 取消选中**将 AWS Glue 数据目录用于表元数据**选项
  - 确认软件配置设置为
	- 发布：**emr-x.x**
	- 应用：Hadoop x.x.x、Spark x.x.x
	- 这里的版本会默认设置为最新版本
  - 确认硬件配置默认值是
	- 实例类型：**m5.xlarge**
	- 实例数：3（1个主节点和2个核心节点）
  - 将安全和访问配置保留为**默认值**
  - 单击**创建集群**以完成。

#### 检查在 EMR 上运行的转换作业的状态

- EMR 集群将需要 6 到 8 分钟的时间来进行配置，另外大约需要一分钟左右的时间来完成 Spark 步骤的执行。
- 执行完 Spark 作业后，集群将终止。
- 要检查作业的状态，请单击集群名称：**analytics-workshop-transformer**
  - 转到 **Steps** 选项卡
  - 在这里你应该看到两个项目：**Spark application** 和 **Setup hadoop debugging**
  - **Spark 应用程序**的状态应从 Pending 变为 Running 到 Completed EMR Step Completion
  
![](/images/1.LabGuide/emr-step-completion.jpg)

  - 一旦 Spark 作业运行完成，EMR 集群将终止
  - 在 EMR > 集群下，您将看到集群状态为已完成所有步骤的消息。 EMR 集群终止
  
![](/images/1.LabGuide/emr-cluster-terminated.jpg)

如果在执行 Spark 作业时出现任何问题，您将看到集群的状态为 Terminated with errors (Step failure)。如果发生故障，您可以浏览 EMR 日志以了解作业失败的根本原因。

#### 验证 - 转换/处理的数据已到达 S3

让我们继续并确认 EMR 转换作业已在 S3 控制台中创建数据集：[https://s3.console.aws.amazon.com/s3/home?region=us-east-1](https://s3.console.aws.amazon.com/s3/home?region=us-east-1)

- 点击 **yourname-analytics-workshop-bucket > data**
- 打开新文件夹 **emr-processed-data**：
  - 确保在此文件夹中创建了 **.parquet** 文件。

重新运行 Glue Crawler

- 前往 Glue 控制台：[https://console.aws.amazon.com/glue/home?region=us-east-1](https://console.aws.amazon.com/glue/home?region=us-east-1)
- 在左侧面板上，单击**爬虫**
  - 选择上一模块中创建的爬虫：**AnalyticsworkshopCrawler**
	- 点击**运行爬虫**
- 您应该会看到状态更改为**正在启动**。
  - 等待几分钟让爬虫运行完成
  - 显示爬虫**添加 1 张表**

您可以转到左侧的数据库部分并确认已添加 **emr_processed_data** 表。

您现在可以在下一模块中使用 Amazon Athena 查询 EMR 作业的结果。 