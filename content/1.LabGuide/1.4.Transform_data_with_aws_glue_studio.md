---
title: "4. 使用 AWS Glue Studio 转换数据"
chapter: false
weight: 4
---

![](/images/1.LabGuide/transform_glue_studio.png)

#### 什么是 AWS Glue Studio？

AWS Glue Studio 是一个新的图形界面，可让您轻松地在 AWS Glue 中创建、运行和监控提取、转换和加载 (ETL) 作业。您可以直观地组合数据转换工作流，并在 AWS Glue 的基于 Apache Spark 的无服务器 ETL 引擎上无缝运行它们。

在本实验中，我们将执行与使用 AWS Glue 转换数据相同的 ETL 过程。。。
但是这一次我们将利用 AWS Glue Studio 中的可视化图形界面！

#### 本次 workshop 的学习成果？

使用 AWS Glue Data Studio，一个图形化界面，轻松地在 AWS Glue 中创建、运行和监控提取、转换和加载 (ETL) 作业。

- 转到 Glue Studio 控制台：https://console.aws.amazon.com/gluestudio/home?region=us-east-1

  - 单击左侧的图标以展开菜单

![](/images/1.LabGuide/glue_studio_0.png)

  - 单击**作业**并选择**空白图**

  - 点击**创建**

![](/images/1.LabGuide/glue_studio_1.png)

- 单击**来源**并选择**S3**

![](/images/1.LabGuide/glue_studio_2.png)

- 在屏幕右侧的配置窗口中单击选项卡**数据源属性 - S3**
- 在 **S3 源**类型下选择**数据目录表**
- 选择以下值
  - 数据库 - **analyticsworkshopdb**
  - 表 - **raw**

![](/images/1.LabGuide/glue_studio_3.png)

- 现在让我们重复相同的步骤从 S3 添加 reference_data。单击 - **来源**并选择 - **S3**

![](/images/1.LabGuide/glue_studio_2.png)

- 在屏幕右侧的配置窗口中单击选项卡**数据源属性 - S3**
- 在 **S3 源**类型下选择**数据目录表**
- 选择以下值
  - 数据库 - **analyticsworkshopdb**
  - 表 - **raw**

![](/images/1.LabGuide/glue_studio_4.png)

- 单击两个 S3 节点中的任意一个

![](/images/1.LabGuide/glue_studio_5.png)

- 单击**转换**并选择**Join**

![](/images/1.LabGuide/glue_studio_6.png)

- 您应该获得如下图所示的可视化图表，并在右侧显示“源节点不足”，因为您需要加入另一个节点（数据源）

![](/images/1.LabGuide/glue_studio_7.png)

- 接下来，单击右侧配置窗口中的 **Transform - Join node** 和 **Node properties**，选择下拉列表并检查所有 S3 数据源，如下面的屏幕截图所示：

![](/images/1.LabGuide/glue_studio_8.png)

  - 单击“**转换**”选项卡，并选择“连接节点”

  - 点击**添加条件**

  - 选择 **track_id** 列作为连接列，如下面的屏幕截图所示。

![](/images/1.LabGuide/glue_studio_9.png)

- 在画布上选择 **Join** 节点后，单击 **Transform** 并选择 **ApplyMapping**

![](/images/1.LabGuide/glue_studio_10.png)

- 你应该得到如下图所示的可视化图表

![](/images/1.LabGuide/glue_studio_11.png)

- 我们将删除未使用的列并为以下列映射新的数据类型：
  - drop 列
	- .track_id
	- parition_0
	- parition_1
	- parition_2
	- parition_3
  - 映射新数据类型
	- track_id **string**

- 您的选择应与下面的屏幕截图相符

![](/images/1.LabGuide/glue_studio_12.png)

- 单击 **Transform - ApplyMapping** 节点

![](/images/1.LabGuide/glue_studio_13.png)

- 单击**目标**并选择 **S3**，如下面的屏幕截图所示

![](/images/1.LabGuide/glue_studio_14.png)

- 在**数据目标属性 - S3** 中，提供如下输入：
  - 格式：**Glue Parquet**
  - 压缩类型：**Snappy**
  - S3 目标位置：**s3://yourname-analytics-workshop-bucket/data/processed-data2/**
  - 数据目录更新选项
	- 选择**在数据目录中创建表并在后续运行中更新架构并添加新分区**
  - 数据库：**analyticsworkshopdb**
  - 表名：**processed-data2**

![](/images/1.LabGuide/glue_studio_15.png)

- 单击**作业详细信息**并使用以下选项进行配置
  - 名称： **AnalyticsOnAWS-GlueStudio**
  - IAM 角色：**AWSGlueServiceRoleDefault**
  - 工作节点数量：**2**
  - 作业书签：**禁用**
  - 重试次数：**1**
  - 作业超时（分钟）：**10**
  - 其余为默认值
  - 点击**保存**

![](/images/1.LabGuide/glue_studio_16.png)

![](/images/1.LabGuide/glue_studio_16-2.png)

- 单击**保存**，您应该会看到“**已成功创建作业**”。通过单击屏幕右上角的**运行**来启动此 ETL 作业。

![](/images/1.LabGuide/glue_studio_17.png)

- 您应该会看到“**成功启动作业**”。单击“**运行详细信息**”以监视您的 ETL 作业。

![](/images/1.LabGuide/glue_studio_18.png)

- 等待几秒钟，您应该会看到您的 ETL 作业运行状态“**成功**”，如下面的屏幕截图所示。

![](/images/1.LabGuide/glue_studio_19.png)

- 如果需要，您可以查看 Glue Studio 生成的 Pyspark 代码并将此代码重用于其他目的。

![](/images/1.LabGuide/glue_studio_20.png)

- 跳转到 Glue 数据目录：https://console.aws.amazon.com/glue/home?region=us-east-1#，您应该会看到在 analyticsworkshopdb 数据库下创建的 processed-data2 表。

干得漂亮！！您已使用 AWS Glue Studio 完成了额外的 ETL 实验。借助 AWS Glue Studio，您可以直观地组合数据转换工作流，并在 AWS Glue 的基于 Apache Spark 的无服务器 ETL 引擎上无缝运行它们。

您可以使用 AWS Glue Studio 从 AWS Marketplace 的第三方数据源获取数据。例如，适用于 Google BigQuery 的 AWS Glue 连接器。在此处阅读有关适用于 Google BigQuery 的 AWS Glue 连接器的更多信息：https://aws.amazon.com/blogs/big-data/migrating-data-from-google-bigquery-to-amazon-s3-using-aws-glue-custom

探索 AWS Glue Studio co 中的可用连接器 
![](/images/1.LabGuide/glue_studio_21.png)